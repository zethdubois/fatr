{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bef5423-f259-4629-a4c6-ada67df9721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes fatr\n",
      "Running ANOVA for: Decision\n",
      "('Scenario',)\n",
      "('Study',)\n",
      "('Fault', 'Study')\n",
      "('Scenario', 'Fault', 'Study')\n",
      "{('Fault',): {'y2': array([0.66666667, 0.83333333]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 2.666666666666666, 'mss': 2.666666666666666, 'dfe': 22.0, 'sse': 4.791666666666667, 'mse': 0.2178030303030303, 'F': 12.243478260869562, 'p': 0.0020286288906186467, 'eta': 0.17391304347826084, 'obs': 48.0, 'critT': 2.073873067904015, 'se': 0.07127503522131787, 'ci': 0.139699069033783, 'lambda': 26.713043478260865, 'power': 0.9985217320274492, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 2.666666666666666, 'mse_gg': 0.2178030303030303, 'F_gg': 12.243478260869562, 'p_gg': 0.0020286288906186467, 'obs_gg': 48.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.07127503522131787, 'ci_gg': 0.139699069033783, 'lambda_gg': 26.713043478260865, 'power_gg': 0.9985217320274492, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 2.666666666666666, 'mse_hf': 0.2178030303030303, 'F_hf': 12.243478260869562, 'p_hf': 0.0020286288906186467, 'obs_hf': 48.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.07127503522131787, 'ci_hf': 0.139699069033783, 'lambda_hf': 26.713043478260865, 'power_hf': 0.9985217320274492, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 2.666666666666666, 'mse_lb': 0.2178030303030303, 'F_lb': 12.243478260869562, 'p_lb': 0.0020286288906186467, 'obs_lb': 48.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.07127503522131787, 'ci_lb': 0.139699069033783, 'lambda_lb': 26.713043478260865, 'power_lb': 0.9985217320274492}, ('Scenario', 'Fault'): {'y2': array([0.75      , 0.8125    , 0.58333333, 0.85416667]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 1.0416666666666665, 'mss': 1.0416666666666665, 'dfe': 22.0, 'sse': 3.291666666666668, 'mse': 0.14962121212121218, 'F': 6.9620253164556924, 'p': 0.01500386028216144, 'eta': 0.07598784194528874, 'obs': 24.0, 'critT': 2.073873067904015, 'se': 0.0835443460494988, 'ci': 0.16374691825701765, 'lambda': 7.594936708860756, 'power': 0.7498528512708454, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 1.0416666666666665, 'mse_gg': 0.14962121212121218, 'F_gg': 6.9620253164556924, 'p_gg': 0.01500386028216144, 'obs_gg': 24.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.0835443460494988, 'ci_gg': 0.16374691825701765, 'lambda_gg': 7.594936708860756, 'power_gg': 0.7498528512708454, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 1.0416666666666665, 'mse_hf': 0.14962121212121218, 'F_hf': 6.9620253164556924, 'p_hf': 0.01500386028216144, 'obs_hf': 24.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.0835443460494988, 'ci_hf': 0.16374691825701765, 'lambda_hf': 7.594936708860756, 'power_hf': 0.7498528512708454, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 1.0416666666666665, 'mse_lb': 0.14962121212121218, 'F_lb': 6.9620253164556924, 'p_lb': 0.01500386028216144, 'obs_lb': 24.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.0835443460494988, 'ci_lb': 0.16374691825701765, 'lambda_lb': 7.594936708860756, 'power_lb': 0.7498528512708454}, ('Scenario', 'Study'): {'y2': array([0.85416667, 0.70833333, 0.70833333, 0.72916667]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 0.6666666666666666, 'mss': 0.6666666666666666, 'dfe': 22.0, 'sse': 2.4583333333333335, 'mse': 0.11174242424242425, 'F': 5.966101694915253, 'p': 0.023076638811863698, 'eta': 0.049999999999999996, 'obs': 24.0, 'critT': 2.073873067904015, 'se': 0.0721987243175518, 'ci': 0.1415094996624015, 'lambda': 6.508474576271187, 'power': 0.6839216064969531, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 0.6666666666666666, 'mse_gg': 0.11174242424242425, 'F_gg': 5.966101694915253, 'p_gg': 0.023076638811863698, 'obs_gg': 24.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.0721987243175518, 'ci_gg': 0.1415094996624015, 'lambda_gg': 6.508474576271187, 'power_gg': 0.6839216064969531, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 0.6666666666666666, 'mse_hf': 0.11174242424242425, 'F_hf': 5.966101694915253, 'p_hf': 0.023076638811863698, 'obs_hf': 24.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.0721987243175518, 'ci_hf': 0.1415094996624015, 'lambda_hf': 6.508474576271187, 'power_hf': 0.6839216064969531, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 0.6666666666666666, 'mse_lb': 0.11174242424242425, 'F_lb': 5.966101694915253, 'p_lb': 0.023076638811863698, 'obs_lb': 24.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.0721987243175518, 'ci_lb': 0.1415094996624015, 'lambda_lb': 6.508474576271187, 'power_lb': 0.6839216064969531}, ('SUBJECT',): {'ss': 2.5, 'sse': 2.125, 'mse': 0.09659090909090909, 'df': 23.0, 'dfe': 22.0}, ('TOTAL',): {'ss': 18.0, 'df': 95.0}, ('WITHIN',): {'ss': 15.5, 'df': 72.0}, ('Scenario', 'SUBJECT'): {'ss': 2.4583333333333335, 'df': 22.0, 'mss': 0.11174242424242425}, ('Fault', 'SUBJECT'): {'ss': 4.791666666666667, 'df': 22.0, 'mss': 0.2178030303030303}, ('Scenario', 'Fault', 'SUBJECT'): {'ss': 3.291666666666668, 'df': 22.0, 'mss': 0.14962121212121218}}\n",
      "\n",
      "\n",
      "\n",
      "Marginal Means for: Decision\n",
      "({'Scenario': array([0.8125, 0.6875]), 'Fault': array([0.58333333, 0.91666667]), 'Study': array([0.8125, 0.6875]), 'ScenarioFault': array([0.75      , 0.875     , 0.41666667, 0.95833333]), 'ScenarioStudy': array([0.95833333, 0.66666667, 0.66666667, 0.70833333]), 'FaultStudy': array([0.625     , 0.54166667, 1.        , 0.83333333]), 'ScenarioFaultStudy': array([0.91666667, 0.58333333, 1.        , 0.75      , 0.33333333,\n",
      "       0.5       , 1.        , 0.91666667])}, {'Scenario': array([0.05693291, 0.06761023]), 'Fault': array([0.07191241, 0.04031495]), 'Study': array([0.05693291, 0.06761023]), 'ScenarioFault': array([0.09028939, 0.06895966, 0.10279899, 0.04166667]), 'ScenarioStudy': array([0.04166667, 0.09829464, 0.09829464, 0.09477599]), 'FaultStudy': array([0.10094661, 0.10389457, 0.        , 0.07770873]), 'ScenarioFaultStudy': array([0.08333333, 0.1486471 , 0.        , 0.13055824, 0.14213381,\n",
      "       0.15075567, 0.        , 0.08333333])}, {'Scenario': [('LOFW',), ('SGTR',)], 'Fault': [('Spoof',), ('True Fault',)], 'Study': [('Dependency',), ('FATR',)], 'ScenarioFault': [('LOFW', 'Spoof'), ('LOFW', 'True Fault'), ('SGTR', 'Spoof'), ('SGTR', 'True Fault')], 'ScenarioStudy': [('LOFW', 'Dependency'), ('LOFW', 'FATR'), ('SGTR', 'Dependency'), ('SGTR', 'FATR')], 'FaultStudy': [('Spoof', 'Dependency'), ('Spoof', 'FATR'), ('True Fault', 'Dependency'), ('True Fault', 'FATR')], 'ScenarioFaultStudy': [('LOFW', 'Spoof', 'Dependency'), ('LOFW', 'Spoof', 'FATR'), ('LOFW', 'True Fault', 'Dependency'), ('LOFW', 'True Fault', 'FATR'), ('SGTR', 'Spoof', 'Dependency'), ('SGTR', 'Spoof', 'FATR'), ('SGTR', 'True Fault', 'Dependency'), ('SGTR', 'True Fault', 'FATR')]})\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyvttbl import DataFrame\n",
    "from pyvttbl.stats import Anova\n",
    "\n",
    "##### SET STUDY VARIABLES\n",
    "## Between-factors >> group on....\n",
    "# Dep: Exptertise, FATR: Study\n",
    "human = True\n",
    "human = False\n",
    "\n",
    "FATR = False\n",
    "FATR = True\n",
    "\n",
    "\n",
    "if FATR:\n",
    "    print(\"** FATR Study **\")\n",
    "    source = os.path.join(\"data\",\"fatr_students.csv\")\n",
    "    bfactor = \"Study\"\n",
    "else:\n",
    "    print(\"** Depend Study **\")\n",
    "    source = os.path.join(\"data\",\"depend_only.csv\")\n",
    "    bfactor = \"Expertise\"\n",
    "\n",
    "\n",
    "temp_csv_path = 'temp_cleaned_data.csv'\n",
    "\n",
    "## Set DVs >> process multiple in one script, or just one at a time; \n",
    "dv_cols = ['Diagnosis Time']  \n",
    "dv_cols = ['Cooper Harper']  \n",
    "dv_cols = ['NasaTLX']\n",
    "dv_cols = ['Decision']\n",
    "\n",
    "\n",
    "# Create a pyvttbl.DataFrame from the cleaned pandas DataFrame\n",
    "df = DataFrame()\n",
    "df_pandas = pd.read_csv(source)\n",
    "\n",
    "# Calculate NasaTLX if this is the DV for analysis\n",
    "if dv_cols[0] != \"NasaTLX\":\n",
    "    ## Drop rows with missing values in relevant columns\n",
    "    # CAUTION! If dv_cols list contains multiple columns, then columns missing row values will obliterate other columns' row values\n",
    "    df_pandas = df_pandas.dropna(subset=dv_cols)\n",
    "    temp_csv_path = 'temp_cleaned_data.csv'\n",
    "    df_pandas.to_csv(temp_csv_path, index=False)\n",
    "else:\n",
    "    print(\"create NasaTLX composit measure...\")\n",
    "    # Invert 'Performance' scores\n",
    "    df_pandas['Performance'] = 11 - df_pandas['Performance']\n",
    "    columns = ['Performance', 'Temporal Demand', 'Frustration Level', 'Mental Demand', 'Effort']\n",
    "    for column in columns:\n",
    "        median = df_pandas[column].median()\n",
    "        df_pandas[column].fillna(median)\n",
    "    # Calculate the NasaTLX composite score\n",
    "    df_pandas['NasaTLX'] = df_pandas[columns].mean(axis=1)\n",
    "    df_pandas.to_csv(temp_csv_path, index=False)\n",
    "\n",
    "df.read_tbl(temp_csv_path)\n",
    "\n",
    "\n",
    "    \n",
    "for dv in dv_cols:\n",
    "    print(f\"Running ANOVA for: {dv}\")\n",
    "    \n",
    "    aov = Anova()\n",
    "    aov.run(df, dv, wfactors=['Scenario', 'Fault'], bfactors=[bfactor])   \n",
    "    aov.truncate(test='gg')\n",
    "\n",
    "    if human:\n",
    "        ### HUMAN READABLE\n",
    "        print(aov)\n",
    "        print(\"\\n\\n\") # this puts spaces between reports when running multiples\n",
    "    else:\n",
    "        ### For the Robots\n",
    "        print(dict(aov))\n",
    "        print(\"\\n\\n\") \n",
    "    \n",
    "        marginal_means = aov.get_marginal_means(['Scenario', 'Fault', bfactor])\n",
    "        print(f\"Marginal Means for: {dv}\")\n",
    "        print(marginal_means)\n",
    "        print(\"\\n\\n\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d5bce71-5a38-47f9-9897-269285d42775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** FATR Study **\n",
      "Running ANOVA for: Decision\n",
      "('Scenario',)\n",
      "('Study',)\n",
      "('Fault', 'Study')\n",
      "('Scenario', 'Fault', 'Study')\n",
      "AOV Dictionary: {('Fault',): {'y2': array([0.66666667, 0.83333333]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 2.666666666666666, 'mss': 2.666666666666666, 'dfe': 22.0, 'sse': 4.791666666666667, 'mse': 0.2178030303030303, 'F': 12.243478260869562, 'p': 0.0020286288906186467, 'eta': 0.17391304347826084, 'obs': 48.0, 'critT': 2.073873067904015, 'se': 0.07127503522131787, 'ci': 0.139699069033783, 'lambda': 26.713043478260865, 'power': 0.9985217320274492, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 2.666666666666666, 'mse_gg': 0.2178030303030303, 'F_gg': 12.243478260869562, 'p_gg': 0.0020286288906186467, 'obs_gg': 48.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.07127503522131787, 'ci_gg': 0.139699069033783, 'lambda_gg': 26.713043478260865, 'power_gg': 0.9985217320274492, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 2.666666666666666, 'mse_hf': 0.2178030303030303, 'F_hf': 12.243478260869562, 'p_hf': 0.0020286288906186467, 'obs_hf': 48.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.07127503522131787, 'ci_hf': 0.139699069033783, 'lambda_hf': 26.713043478260865, 'power_hf': 0.9985217320274492, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 2.666666666666666, 'mse_lb': 0.2178030303030303, 'F_lb': 12.243478260869562, 'p_lb': 0.0020286288906186467, 'obs_lb': 48.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.07127503522131787, 'ci_lb': 0.139699069033783, 'lambda_lb': 26.713043478260865, 'power_lb': 0.9985217320274492}, ('Scenario', 'Fault'): {'y2': array([0.75      , 0.8125    , 0.58333333, 0.85416667]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 1.0416666666666665, 'mss': 1.0416666666666665, 'dfe': 22.0, 'sse': 3.291666666666668, 'mse': 0.14962121212121218, 'F': 6.9620253164556924, 'p': 0.01500386028216144, 'eta': 0.07598784194528874, 'obs': 24.0, 'critT': 2.073873067904015, 'se': 0.0835443460494988, 'ci': 0.16374691825701765, 'lambda': 7.594936708860756, 'power': 0.7498528512708454, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 1.0416666666666665, 'mse_gg': 0.14962121212121218, 'F_gg': 6.9620253164556924, 'p_gg': 0.01500386028216144, 'obs_gg': 24.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.0835443460494988, 'ci_gg': 0.16374691825701765, 'lambda_gg': 7.594936708860756, 'power_gg': 0.7498528512708454, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 1.0416666666666665, 'mse_hf': 0.14962121212121218, 'F_hf': 6.9620253164556924, 'p_hf': 0.01500386028216144, 'obs_hf': 24.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.0835443460494988, 'ci_hf': 0.16374691825701765, 'lambda_hf': 7.594936708860756, 'power_hf': 0.7498528512708454, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 1.0416666666666665, 'mse_lb': 0.14962121212121218, 'F_lb': 6.9620253164556924, 'p_lb': 0.01500386028216144, 'obs_lb': 24.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.0835443460494988, 'ci_lb': 0.16374691825701765, 'lambda_lb': 7.594936708860756, 'power_lb': 0.7498528512708454}, ('Scenario', 'Study'): {'y2': array([0.85416667, 0.70833333, 0.70833333, 0.72916667]), 'df': 1.0, 'eps_gg': 1.0, 'eps_hf': 1.0, 'eps_lb': 1.0, 'ss': 0.6666666666666666, 'mss': 0.6666666666666666, 'dfe': 22.0, 'sse': 2.4583333333333335, 'mse': 0.11174242424242425, 'F': 5.966101694915253, 'p': 0.023076638811863698, 'eta': 0.049999999999999996, 'obs': 24.0, 'critT': 2.073873067904015, 'se': 0.0721987243175518, 'ci': 0.1415094996624015, 'lambda': 6.508474576271187, 'power': 0.6839216064969531, 'df_gg': 1.0, 'dfe_gg': 22.0, 'mss_gg': 0.6666666666666666, 'mse_gg': 0.11174242424242425, 'F_gg': 5.966101694915253, 'p_gg': 0.023076638811863698, 'obs_gg': 24.0, 'critT_gg': 2.073873067904015, 'se_gg': 0.0721987243175518, 'ci_gg': 0.1415094996624015, 'lambda_gg': 6.508474576271187, 'power_gg': 0.6839216064969531, 'df_hf': 1.0, 'dfe_hf': 22.0, 'mss_hf': 0.6666666666666666, 'mse_hf': 0.11174242424242425, 'F_hf': 5.966101694915253, 'p_hf': 0.023076638811863698, 'obs_hf': 24.0, 'critT_hf': 2.073873067904015, 'se_hf': 0.0721987243175518, 'ci_hf': 0.1415094996624015, 'lambda_hf': 6.508474576271187, 'power_hf': 0.6839216064969531, 'df_lb': 1.0, 'dfe_lb': 22.0, 'mss_lb': 0.6666666666666666, 'mse_lb': 0.11174242424242425, 'F_lb': 5.966101694915253, 'p_lb': 0.023076638811863698, 'obs_lb': 24.0, 'critT_lb': 2.073873067904015, 'se_lb': 0.0721987243175518, 'ci_lb': 0.1415094996624015, 'lambda_lb': 6.508474576271187, 'power_lb': 0.6839216064969531}, ('SUBJECT',): {'ss': 2.5, 'sse': 2.125, 'mse': 0.09659090909090909, 'df': 23.0, 'dfe': 22.0}, ('TOTAL',): {'ss': 18.0, 'df': 95.0}, ('WITHIN',): {'ss': 15.5, 'df': 72.0}, ('Scenario', 'SUBJECT'): {'ss': 2.4583333333333335, 'df': 22.0, 'mss': 0.11174242424242425}, ('Fault', 'SUBJECT'): {'ss': 4.791666666666667, 'df': 22.0, 'mss': 0.2178030303030303}, ('Scenario', 'Fault', 'SUBJECT'): {'ss': 3.291666666666668, 'df': 22.0, 'mss': 0.14962121212121218}}\n",
      "Marginal Means: ({'Scenario': array([0.8125, 0.6875]), 'Fault': array([0.58333333, 0.91666667]), 'Study': array([0.8125, 0.6875]), 'ScenarioFault': array([0.75      , 0.875     , 0.41666667, 0.95833333]), 'ScenarioStudy': array([0.95833333, 0.66666667, 0.66666667, 0.70833333]), 'FaultStudy': array([0.625     , 0.54166667, 1.        , 0.83333333]), 'ScenarioFaultStudy': array([0.91666667, 0.58333333, 1.        , 0.75      , 0.33333333,\n",
      "       0.5       , 1.        , 0.91666667])}, {'Scenario': array([0.05693291, 0.06761023]), 'Fault': array([0.07191241, 0.04031495]), 'Study': array([0.05693291, 0.06761023]), 'ScenarioFault': array([0.09028939, 0.06895966, 0.10279899, 0.04166667]), 'ScenarioStudy': array([0.04166667, 0.09829464, 0.09829464, 0.09477599]), 'FaultStudy': array([0.10094661, 0.10389457, 0.        , 0.07770873]), 'ScenarioFaultStudy': array([0.08333333, 0.1486471 , 0.        , 0.13055824, 0.14213381,\n",
      "       0.15075567, 0.        , 0.08333333])}, {'Scenario': [('LOFW',), ('SGTR',)], 'Fault': [('Spoof',), ('True Fault',)], 'Study': [('Dependency',), ('FATR',)], 'ScenarioFault': [('LOFW', 'Spoof'), ('LOFW', 'True Fault'), ('SGTR', 'Spoof'), ('SGTR', 'True Fault')], 'ScenarioStudy': [('LOFW', 'Dependency'), ('LOFW', 'FATR'), ('SGTR', 'Dependency'), ('SGTR', 'FATR')], 'FaultStudy': [('Spoof', 'Dependency'), ('Spoof', 'FATR'), ('True Fault', 'Dependency'), ('True Fault', 'FATR')], 'ScenarioFaultStudy': [('LOFW', 'Spoof', 'Dependency'), ('LOFW', 'Spoof', 'FATR'), ('LOFW', 'True Fault', 'Dependency'), ('LOFW', 'True Fault', 'FATR'), ('SGTR', 'Spoof', 'Dependency'), ('SGTR', 'Spoof', 'FATR'), ('SGTR', 'True Fault', 'Dependency'), ('SGTR', 'True Fault', 'FATR')]})\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyvttbl import DataFrame\n",
    "from pyvttbl.stats import Anova\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Define study variables\n",
    "# Set to True for FATR study, False for Depend study\n",
    "STUDY_FATR = False  \n",
    "STUDY_FATR = True\n",
    "# True for human-readable output, False for structured data\n",
    "HUMAN_READABLE = True  \n",
    "HUMAN_READABLE = False\n",
    "\n",
    "## Set DVs >> process multiple in one list, or just one at a time seems easier... \n",
    "DV = 'Diagnosis Time'\n",
    "DV = 'Cooper Harper'\n",
    "DV = 'NasaTLX'\n",
    "DV = 'Decision'\n",
    "\n",
    "# Paths and filenames\n",
    "DATA_DIR = 'data'\n",
    "TEMP_CSV_PATH = 'temp_cleaned_data.csv'\n",
    "\n",
    "# Determine study based on STUDY_FATR flag\n",
    "if STUDY_FATR:\n",
    "    print(\"** FATR Study **\")\n",
    "    source_filename = 'fatr_students.csv'\n",
    "    between_factor = \"Study\"\n",
    "else:\n",
    "    print(\"** Depend Study **\")\n",
    "    source_filename = 'depend_only.csv'\n",
    "    between_factor = \"Expertise\"\n",
    "\n",
    "source_path = os.path.join(DATA_DIR, source_filename)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_pandas = pd.read_csv(source_path)\n",
    "\n",
    "if DV == \"NasaTLX\":\n",
    "    print(\"Creating NasaTLX composite measure...\")\n",
    "    # Invert 'Performance' scores and fill missing values with median\n",
    "    df_pandas['Performance'] = 11 - df_pandas['Performance']\n",
    "    columns = ['Performance', 'Temporal Demand', 'Frustration Level', 'Mental Demand', 'Effort']\n",
    "    for column in columns:\n",
    "        median = df_pandas[column].median()\n",
    "        df_pandas[column].fillna(median, inplace=True)\n",
    "    # Calculate the NasaTLX composite score\n",
    "    df_pandas['NasaTLX'] = df_pandas[columns].mean(axis=1)\n",
    "else:\n",
    "    # Drop rows with missing values in the DV\n",
    "    df_pandas.dropna(subset=[DV], inplace=True)\n",
    "\n",
    "# Save cleaned data to temporary CSV\n",
    "df_pandas.to_csv(TEMP_CSV_PATH, index=False)\n",
    "\n",
    "# Load data into pyvttbl DataFrame for ANOVA\n",
    "df_pyvttbl = DataFrame()\n",
    "df_pyvttbl.read_tbl(TEMP_CSV_PATH)\n",
    "\n",
    "# ANOVA settings\n",
    "wfactors = ['Scenario', 'Fault']\n",
    "bfactors = [between_factor]\n",
    "\n",
    "# Run ANOVA\n",
    "print(f\"Running ANOVA for: {DV}\")\n",
    "aov = Anova()\n",
    "aov.run(df_pyvttbl, DV, wfactors=wfactors, bfactors=bfactors)\n",
    "aov.truncate(test='gg')\n",
    "\n",
    "# Human-readable output\n",
    "if HUMAN_READABLE:\n",
    "    print(aov)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Convert aov_dict and marginal_means to pretty-printed string format\n",
    "aov_dict_str = pprint.pformat(aov_dict)\n",
    "marginal_means_str = pprint.pformat(marginal_means)\n",
    "\n",
    "# Combine the two strings with a separator for clarity\n",
    "combined_summary = f\"ANOVA Results:\\n{aov_dict_str}\\n\\nMarginal Means:\\n{marginal_means_str}\"\n",
    "\n",
    "\n",
    "# These variables now hold the raw data in whatever format they originally had\n",
    "# For example, aov_dict could be a dictionary with various statistics,\n",
    "# and marginal_means could be a pandas DataFrame or a dictionary\n",
    "\n",
    "if not HUMAN_READABLE:\n",
    "    # Directly printing without conversion\n",
    "    print(\"AOV Dictionary:\", aov_dict)\n",
    "    print(\"Marginal Means:\", marginal_means)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37fde805-c62b-4475-9cde-19dc2d7cc88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from Claude claude-instant-1.2 for LaTeX\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"background-color: #f6f8fa; padding: 10px; border-left: 6px solid #ccc; font-family: monospace; overflow: auto;\">\n",
       "<pre><code style=\"color: #333;\">\\begin{description}\n",
       "\\item[Main effects]\n",
       "\\begin{itemize}\n",
       "\\item \\textbf{Fault:} $F(1, 22) = 12.24$, $p = 0.002$, $\\eta^2 = 0.17$\n",
       "The estimated marginal means for Fault were $y_1 = 0.58$ and $y_2 = 0.92$. The True Fault condition had a higher mean decision value than the Spoof condition.\n",
       "\\item \\textbf{Scenario:} $F(1, 22) = 5.97$, $p = 0.023$, $\\eta^2 = 0.05$  \n",
       "The estimated marginal means for Scenario were $y_1 = 0.81$ and $y_2 = 0.69$. The LOFW scenario had a higher mean decision value than the SGTR scenario.\n",
       "\\item \\textbf{Study:} $F(1, 22) = 5.97$, $p = 0.023$, $\\eta^2 = 0.05$\n",
       "The estimated marginal means for Study were $y_1 = 0.81$ and $y_2 = 0.69$. The Dependency study had a higher mean decision value than the FATR study.\n",
       "\\end{itemize}\n",
       "\n",
       "\\item[Two-way interactions]\n",
       "\\begin{itemize}\n",
       "\\item \\textbf{Scenario $\\times$ Fault:} $F(1, 22) = 6.96$, $p = 0.015$, $\\eta^2 = 0.08$\n",
       "The estimated marginal means were $y_{11} = 0.75$, $y_{12} = 0.81$, $y_{21} = 0.58$, $y_{22} = 0.86$. The mean decision value was highest for the LOFW true fault condition and lowest for the SGTR spoof condition.\n",
       "\\end{itemize}\n",
       "\n",
       "\\item[Summary]\n",
       "The main effects of Fault, Scenario, and Study were all statistically significant. The interaction between Scenario and Fault was also significant. The True Fault condition and LOFW scenario tended to result in higher mean decision values compared to the other conditions.\n",
       "\\end{description}</code></pre>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import anthropic\n",
    "from IPython.display import display, Markdown\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "model_switch = 0\n",
    "\n",
    "model_map = {\n",
    "    0: \"claude-instant-1.2\",\n",
    "    1: \"claude-3-opus-20240229\",\n",
    "}\n",
    "\n",
    "model = model_map.get(model_switch, \"claude-instant-1.2\")\n",
    "\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"You will be provided with two pieces of information:\\n\\n    A dictionary containing the results of an ANOVA, including F-values, p-values, effect sizes, and other relevant statistics for main effects, interactions, and other sources of variance.\\n    A dictionary containing the estimated marginal means and standard errors for each factor and their combinations.\\n\\nYour task is to create a well-structured and formatted LaTeX report that interprets the ANOVA results and includes the estimated marginal means and standard errors. The report should follow this outline:\\n\\n    If the data contains results which are not significant, then disregard that variable. The statistical significance score for p=0.05 determines what needs to be reported.\\n\\n    Begin with a brief introductory statement about the effects on the dependent variable.\\n    Report the main effects, including:\\n        F-values, p-values, and effect sizes for each main effect\\n        Interpretation of the estimated marginal means and standard errors for each level of the main effects\\n    Report the two-way interactions, including:\\n        F-values, p-values, and effect sizes for each two-way interaction\\n        Interpretation of the estimated marginal means and standard errors for each combination of the interacting factors\\n    Report the three-way interaction, if present, including:\\n        F-value, p-value, and effect size for the three-way interaction\\n        Interpretation of the estimated marginal means and standard errors for each combination of the interacting factors\\n    Conclude with a summary statement highlighting the key findings and the complex interplay among the factors.\\n\\nUse the following LaTeX formatting guidelines:\\n\\n    Use the description environment for the overall structure\\n    Use paragraph for the main sections (e.g., Main effects, Two-way interactions)\\n    Use itemize for individual findings within each section\\n    Use appropriate LaTeX commands for mathematical symbols and equations (e.g., $F(1, 22) = 15.30$, $p < .001$, $\\\\eta^2 = .13$)\\n    Indent the LaTeX code for better readability and structure\\n\\nProvide the complete LaTeX code, without preamble and document environment. The output should be formatted in a raw markdown panel for easy copy.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": combined_summary\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# HTML template for the code block\n",
    "print(f'Results from Claude {model} for LaTeX')\n",
    "\n",
    "html_template = f\"\"\"\n",
    "<div style=\"background-color: #f6f8fa; padding: 10px; border-left: 6px solid #ccc; font-family: monospace; overflow: auto;\">\n",
    "<pre><code style=\"color: #333;\">{message_formatted}</code></pre>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_template))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65b9feb-5a0f-4e42-8a40-710aa118a007",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate the summary text\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m summary_text \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43maov_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarginal_means\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Proceed with your anthropic API call, inserting the summary_text into the 'text' field\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01manthropic\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m, in \u001b[0;36msummarize_results\u001b[0;34m(aov_dict, marginal_means)\u001b[0m\n\u001b[1;32m      6\u001b[0m     summary \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m summary \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMarginal Means:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmarginal_means\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     10\u001b[0m     summary \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# This is a simplified example. You'd replace it with actual summarization logic\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Example function to summarize ANOVA results and marginal means\n",
    "def summarize_results(aov_dict, marginal_means):\n",
    "    # Placeholder for the summary. You'd fill this in with actual data extraction and formatting\n",
    "    summary = \"ANOVA Summary:\\n\"\n",
    "    for key, value in aov_dict.items():\n",
    "        summary += f\"{key}: {value}\\n\"\n",
    "    \n",
    "    summary += \"\\nMarginal Means:\\n\"\n",
    "    for key, value in marginal_means.items():\n",
    "        summary += f\"{key}: {value}\\n\"\n",
    "    \n",
    "    # This is a simplified example. You'd replace it with actual summarization logic\n",
    "    return summary\n",
    "\n",
    "# Generate the summary text\n",
    "summary_text = summarize_results(aov_dict, marginal_means)\n",
    "\n",
    "# Proceed with your anthropic API call, inserting the summary_text into the 'text' field\n",
    "import anthropic\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "model_switch = 0\n",
    "model_map = {\n",
    "    0: \"claude-instant-1.2\",\n",
    "    1: \"claude-3-opus-20240229\",\n",
    "}\n",
    "model = model_map.get(model_switch, \"claude-instant-1.2\")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    system=\"You will be provided with two pieces of information:\\n\\n    A dictionary containing the results of an ANOVA, including F-values, p-values, effect sizes, and other relevant statistics for main effects, interactions, and other sources of variance.\\n    A dictionary containing the estimated marginal means and standard errors for each factor and their combinations.\\n\\nYour task is to create a well-structured and formatted LaTeX report that interprets the ANOVA results and includes the estimated marginal means and standard errors. The report should follow this outline:\\n\\n    If the data contains results which are not significant, then disregard that variable. The statistical significance score for p=0.05 determines what needs to be reported.\\n\\n    Begin with a brief introductory statement about the effects on the dependent variable.\\n    Report the main effects, including:\\n        F-values, p-values, and effect sizes for each main effect\\n        Interpretation of the estimated marginal means and standard errors for each level of the main effects\\n    Report the two-way interactions, including:\\n        F-values, p-values, and effect sizes for each two-way interaction\\n        Interpretation of the estimated marginal means and standard errors for each combination of the interacting factors\\n    Report the three-way interaction, if present, including:\\n        F-value, p-value, and effect size for the three-way interaction\\n        Interpretation of the estimated marginal means and standard errors for each combination of the interacting factors\\n    Conclude with a summary statement highlighting the key findings and the complex interplay among the factors.\\n\\nUse the following LaTeX formatting guidelines:\\n\\n    Use the description environment for the overall structure\\n    Use paragraph for the main sections (e.g., Main effects, Two-way interactions)\\n    Use itemize for individual findings within each section\\n    Use appropriate LaTeX commands for mathematical symbols and equations (e.g., $F(1, 22) = 15.30$, $p < .001$, $\\\\eta^2 = .13$)\\n    Indent the LaTeX code for better readability and structure\\n\\nProvide the complete LaTeX code, without preamble and document environment. The output should be formatted in a raw markdown panel for easy copy.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": summary_text  # Use the generated summary text here\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Assuming 'message_formatted' contains the response you want to display as code\n",
    "message_formatted = \"Your formatted message or response from Anthropic API here\"\n",
    "\n",
    "# HTML template for the code block\n",
    "print(f'Results from Claude {model} for LaTeX')\n",
    "\n",
    "html_template = f\"\"\"\n",
    "<div style=\"background-color: #f6f8fa; padding: 10px; border-left: 6px solid #ccc; font-family: monospace; overflow: auto;\">\n",
    "<pre><code style=\"color: #333;\">{message_formatted}</code></pre>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_template))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de082f1-7785-4ed3-8ccb-9dab08ac2d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
